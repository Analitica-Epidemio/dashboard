#!/usr/bin/env python3
"""
üó∫Ô∏è SEED - Capas GIS del Instituto Geogr√°fico Nacional (IGN)

Descarga y carga capas geogr√°ficas autom√°ticamente desde el servicio WFS del IGN
para an√°lisis epidemiol√≥gico.

FUENTE DE DATOS:
----------------
Nombre: Instituto Geogr√°fico Nacional - Capas SIG
Portal WFS: https://wms.ign.gob.ar/geoserver/ign/ows
Portal Web: https://www.ign.gob.ar/NuestrasActividades/InformacionGeoespacial/CapasSIG
Sistema de coordenadas: WGS 84 (EPSG:4326)

CAPAS DESCARGADAS AUTOM√ÅTICAMENTE:
-----------------------------------
1. **Hidrograf√≠a Perenne**: Cursos de agua permanentes (r√≠os, arroyos)
   - TypeName WFS: ign:lineas_de_aguas_continentales_perenne
   - √ötil para: An√°lisis de enfermedades transmitidas por vectores (dengue, zika)
   - Tipo: LineString

2. **Hidrograf√≠a Intermitente**: Cursos de agua temporales
   - TypeName WFS: ign:lineas_de_aguas_continentales_intermitentes
   - √ötil para: An√°lisis de vectores en zonas con agua estacional
   - Tipo: LineString

3. **√Åreas Urbanas**: Plantas urbanas de localidades
   - TypeName WFS: ign:areas_de_asentamientos_y_edificios_020105
   - √ötil para: An√°lisis de densidad poblacional y distribuci√≥n de eventos
   - Tipo: Polygon

DESCARGA AUTOM√ÅTICA:
--------------------
Este script SIEMPRE descarga las capas directamente desde el servicio WFS del IGN.
NO usa archivos locales. Requiere conexi√≥n a internet estable.

REQUISITOS:
-----------
- PostGIS habilitado en PostgreSQL
- Tablas capa_hidrografia y capa_area_urbana creadas (migraci√≥n aplicada)
- Conexi√≥n a internet para descargar desde WFS
- Dependencias: geopandas, shapely, geoalchemy2, requests

USO:
----
  python app/scripts/seeds/seed_capas_gis_ign.py

TIEMPO ESTIMADO: 3-5 minutos (dependiendo de la velocidad de descarga)
"""

import sys
from pathlib import Path

import geopandas as gpd
import requests
from shapely.geometry import LineString, Polygon
from sqlalchemy import Connection, text

# Agregar el directorio ra√≠z al path
sys.path.append(str(Path(__file__).parent.parent.parent))


# URLs WFS del IGN para descarga directa
WFS_URLS = {
    'hidrografia_perenne': 'https://wms.ign.gob.ar/geoserver/ign/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=ign:lineas_de_aguas_continentales_perenne&outputFormat=application/json',
    'hidrografia_intermitente': 'https://wms.ign.gob.ar/geoserver/ign/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=ign:lineas_de_aguas_continentales_intermitentes&outputFormat=application/json',
    'areas_urbanas': 'https://wms.ign.gob.ar/geoserver/ign/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=ign:areas_de_asentamientos_y_edificios_020105&outputFormat=application/json',
}


def descargar_desde_wfs_chunked(capa_key: str, chunk_size: int = 5000, timeout: int = 300):
    """
    Descarga una capa GIS desde el servicio WFS del IGN con cach√© local,
    proces√°ndola en chunks para evitar problemas de memoria.

    Args:
        capa_key: Clave de la capa en WFS_URLS
        chunk_size: Tama√±o de chunk para procesar
        timeout: Timeout en segundos para la descarga

    Yields:
        GeoDataFrame con chunks de datos
    """
    from app.scripts.seeds.cache_helper import download_with_cache
    import json
    from io import StringIO

    if capa_key not in WFS_URLS:
        print(f"‚ùå Capa desconocida: {capa_key}")
        return

    url = WFS_URLS[capa_key]
    print(f"üì• Descargando capa GIS: {capa_key}...")
    print(f"   URL: {url[:80]}...")

    try:
        # Descargar con cach√© (7 d√≠as de validez)
        geojson_content = download_with_cache(
            url=url,
            cache_key=f"gis_ign_{capa_key}",
            max_age_days=7,
            timeout=timeout,
            verify_ssl=True
        )

        # Parsear GeoJSON
        geojson_data = json.loads(geojson_content)
        features = geojson_data.get('features', [])
        total_features = len(features)

        print(f"‚úÖ Descargados {total_features:,} features de {capa_key}")

        # Procesar en chunks
        for i in range(0, total_features, chunk_size):
            chunk_features = features[i:i + chunk_size]

            # Crear un GeoJSON temporal para este chunk
            chunk_geojson = {
                'type': 'FeatureCollection',
                'features': chunk_features
            }

            # Convertir a GeoDataFrame
            chunk_json_str = json.dumps(chunk_geojson)
            gdf = gpd.read_file(StringIO(chunk_json_str))

            # Asegurar que est√© en EPSG:4326
            if gdf.crs and gdf.crs.to_epsg() != 4326:
                gdf = gdf.to_crs(epsg=4326)

            yield gdf

    except Exception as e:
        print(f"‚ùå Error procesando {capa_key}: {e}")
        import traceback
        traceback.print_exc()


def seed_hidrografia(conn: Connection) -> int:
    """
    Carga cursos de agua descarg√°ndolos desde el servicio WFS del IGN.

    IMPORTANTE: Siempre descarga desde WFS, nunca usa archivos locales.

    Args:
        conn: Conexi√≥n SQLAlchemy

    Returns:
        N√∫mero de cursos de agua insertados
    """
    print("\n" + "="*70)
    print("üíß CARGANDO HIDROGRAF√çA (Cursos de Agua)")
    print("="*70)

    total_inserted = 0

    # Capas de hidrograf√≠a desde WFS
    capas_hidro = [
        ('hidrografia_perenne', 'R√≠o/Arroyo Perenne'),
        ('hidrografia_intermitente', 'Curso Intermitente')
    ]

    for capa_key, tipo_curso in capas_hidro:
        print(f"\nüìç Procesando: {tipo_curso}")

        # Descargar y procesar en chunks desde WFS
        inserted = 0
        batch_size = 2000  # üöÄ 4x m√°s grande = menos round-trips a DB
        chunk_num = 0

        for gdf_chunk in descargar_desde_wfs_chunked(capa_key, chunk_size=5000):
            chunk_num += 1
            print(f"\n   üì¶ Chunk {chunk_num} ({len(gdf_chunk):,} features)...")

            # Procesar el chunk en batches m√°s peque√±os para inserci√≥n
            for i in range(0, len(gdf_chunk), batch_size):
                batch = gdf_chunk.iloc[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                total_batches = (len(gdf_chunk) + batch_size - 1) // batch_size

                # üöÄ Print solo cada 5 batches (reduce I/O overhead)
                if batch_num % 5 == 1 or batch_num == total_batches:
                    print(f"      ‚Üí Batch {batch_num}/{total_batches}...", end=" ", flush=True)

                values_list = []
                for idx, row in batch.iterrows():
                    # Extraer nombre si existe
                    nombre = None
                    if 'nombre' in row:
                        nombre = str(row['nombre'])[:200] if row['nombre'] else None
                    elif 'nam' in row:
                        nombre = str(row['nam'])[:200] if row['nam'] else None

                    # Escapar comillas simples en el nombre (SQL injection prevention)
                    if nombre:
                        nombre = nombre.replace("'", "''")

                    # Convertir geometr√≠a a WKT
                    geom_wkt = row.geometry.wkt if row.geometry else None

                    if geom_wkt:
                        # Escapar comillas simples en la geometr√≠a tambi√©n
                        geom_wkt = geom_wkt.replace("'", "''")

                        values_list.append(f"""(
                            {f"'{nombre}'" if nombre else 'NULL'},
                            '{tipo_curso}',
                            ST_GeomFromText('{geom_wkt}', 4326),
                            'IGN',
                            CURRENT_TIMESTAMP,
                            CURRENT_TIMESTAMP
                        )""")

                if values_list:
                    stmt = text(f"""
                        INSERT INTO capa_hidrografia (
                            nombre, tipo, geometria, fuente, created_at, updated_at
                        ) VALUES {','.join(values_list)}
                    """)

                    try:
                        conn.execute(stmt)
                        # üöÄ NO commit aqu√≠ - solo al final
                        inserted += len(values_list)
                        if batch_num % 5 == 1 or batch_num == total_batches:
                            print("‚úÖ")
                    except Exception as e:
                        print(f"‚ùå Error: {e}")
                        conn.rollback()
                        continue

        # üöÄ Commit UNA VEZ al final de cada capa
        conn.commit()
        print(f"\n‚úÖ Insertados {inserted:,} {tipo_curso}")
        total_inserted += inserted

    print("\n" + "="*70)
    print(f"‚úÖ HIDROGRAF√çA CARGADA: {total_inserted:,} cursos de agua")
    print("="*70)

    return total_inserted


def seed_areas_urbanas(conn: Connection) -> int:
    """
    Carga √°reas urbanas descarg√°ndolas desde el servicio WFS del IGN.

    IMPORTANTE: Siempre descarga desde WFS, nunca usa archivos locales.

    Args:
        conn: Conexi√≥n SQLAlchemy

    Returns:
        N√∫mero de √°reas urbanas insertadas
    """
    print("\n" + "="*70)
    print("üèôÔ∏è  CARGANDO √ÅREAS URBANAS")
    print("="*70)

    # Descargar y procesar en chunks desde WFS
    inserted = 0
    batch_size = 2000  # üöÄ 4x m√°s grande
    chunk_num = 0

    for gdf_chunk in descargar_desde_wfs_chunked('areas_urbanas', chunk_size=5000):
        chunk_num += 1
        print(f"\n   üì¶ Chunk {chunk_num} ({len(gdf_chunk):,} features)...")

        # Procesar el chunk en batches m√°s peque√±os para inserci√≥n
        for i in range(0, len(gdf_chunk), batch_size):
            batch = gdf_chunk.iloc[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (len(gdf_chunk) + batch_size - 1) // batch_size

            # üöÄ Print solo cada 5 batches
            if batch_num % 5 == 1 or batch_num == total_batches:
                print(f"      ‚Üí Batch {batch_num}/{total_batches}...", end=" ", flush=True)

            values_list = []
            for idx, row in batch.iterrows():
                # Extraer nombre y poblaci√≥n si existen
                nombre = None
                poblacion = None

                if 'nombre' in row:
                    nombre = str(row['nombre'])[:200] if row['nombre'] else None
                elif 'nam' in row:
                    nombre = str(row['nam'])[:200] if row['nam'] else None

                # Escapar comillas simples en el nombre (SQL injection prevention)
                if nombre:
                    nombre = nombre.replace("'", "''")

                if 'poblacion' in row:
                    try:
                        poblacion = int(row['poblacion'])
                    except (ValueError, TypeError):
                        poblacion = None

                # Convertir geometr√≠a a WKT
                geom_wkt = row.geometry.wkt if row.geometry else None

                if geom_wkt:
                    # Escapar comillas simples en la geometr√≠a tambi√©n
                    geom_wkt = geom_wkt.replace("'", "''")

                    values_list.append(f"""(
                        {f"'{nombre}'" if nombre else 'NULL'},
                        NULL,
                        NULL,
                        {poblacion if poblacion else 'NULL'},
                        ST_GeomFromText('{geom_wkt}', 4326),
                        'IGN',
                        CURRENT_TIMESTAMP,
                        CURRENT_TIMESTAMP
                    )""")

            if values_list:
                stmt = text(f"""
                    INSERT INTO capa_area_urbana (
                        nombre, id_departamento_indec, id_departamento, poblacion,
                        geometria, fuente, created_at, updated_at
                    ) VALUES {','.join(values_list)}
                """)

                try:
                    conn.execute(stmt)
                    # üöÄ NO commit aqu√≠
                    inserted += len(values_list)
                    if batch_num % 5 == 1 or batch_num == total_batches:
                        print("‚úÖ")
                except Exception as e:
                    print(f"‚ùå Error: {e}")
                    conn.rollback()
                    continue

    # üöÄ Commit UNA VEZ al final
    conn.commit()

    print("\n" + "="*70)
    print(f"‚úÖ √ÅREAS URBANAS CARGADAS: {inserted:,}")
    print("="*70)

    return inserted


if __name__ == "__main__":
    import os
    from sqlalchemy import create_engine

    DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://epidemiologia_user:epidemiologia_password@localhost:5432/epidemiologia_db")
    if "postgresql+asyncpg" in DATABASE_URL:
        DATABASE_URL = DATABASE_URL.replace("postgresql+asyncpg://", "postgresql://")

    engine = create_engine(DATABASE_URL)

    print("\n" + "="*70)
    print("üó∫Ô∏è  SEED CAPAS GIS - INSTITUTO GEOGR√ÅFICO NACIONAL")
    print("="*70)
    print("\nEste proceso descarga autom√°ticamente capas GIS desde:")
    print("  üåê https://wms.ign.gob.ar/geoserver/ign/ows")
    print("\nCapas a descargar:")
    print("  üíß Hidrograf√≠a Perenne (~52,000 features)")
    print("  üíß Hidrograf√≠a Intermitente (~20,000 features)")
    print("  üèôÔ∏è  √Åreas Urbanas (~5,000 features)")
    print("\n‚è±Ô∏è  Tiempo estimado: 3-5 minutos")
    print("‚ö†Ô∏è  IMPORTANTE: Requiere conexi√≥n a internet estable")
    print("="*70)

    try:
        with engine.connect() as conn:
            # Verificar PostGIS
            result = conn.execute(text("SELECT PostGIS_Version()")).fetchone()
            print(f"\n‚úÖ PostGIS detectado: {result[0]}")

            # Cargar capas desde WFS
            hidro_count = seed_hidrografia(conn)
            areas_count = seed_areas_urbanas(conn)

            # Resumen
            print("\n" + "="*70)
            print("‚úÖ SEED GIS COMPLETADO")
            print("="*70)
            print(f"\n  ‚úÖ {hidro_count:,} Cursos de agua")
            print(f"  ‚úÖ {areas_count:,} √Åreas urbanas")
            print("="*70)

    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
